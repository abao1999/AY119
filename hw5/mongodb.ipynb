{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ay119: NoSQL databases: MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will work with one of the most popular (document-based) NoSQL databases - [`MongoDB`](https://mongodb.com). \n",
    "Concretely, we will:\n",
    "\n",
    "- Deploy a `MongoDB` database using `docker` \n",
    "    - Set up `docker`\n",
    "- Fetch some public transient alerts from the [Zwicky Transient Facility](https://ztf.caltech.edu), ingest them into the database, and create indices in the database for faster queries\n",
    "- Query the database using python\n",
    "    - Inspect the contents of an alert packet\n",
    "    - Construct and plot a light curve\n",
    "    - Plot the cutout images from an alert packet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequisites:\n",
    "\n",
    "- `Docker`\n",
    "- `python>=3.7`\n",
    "- python libraries: `pymongo` `requests` `matplotlib` `numpy` `pandas` `astropy` `tqdm`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up\n",
    "\n",
    "For a quick introduction into NoSQL databases, please read [these slides](https://github.com/dmitryduev/ay119/raw/master/databases/Ay119_NoSQL_databases.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the help from `docker`, setting up `MongoDB` on the local machine will take only a few simple steps.\n",
    "\n",
    "`Docker` uses OS-level virtualization to deliver software in packages called containers. Containers are isolated from one another and bundle their own software, libraries and configuration files; they can communicate with each other through well-defined channels. All containers are run by a single operating system kernel and therefore use fewer resources than virtual machines. [\\[Wikipedia\\]](https://en.wikipedia.org/wiki/Docker_(software))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the [instructions from docker.com](https://docs.docker.com/engine/install/) to install and set up `docker` on your platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo usermod -a -G docker abao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker:x:999:abao\r\n"
     ]
    }
   ],
   "source": [
    "!grep docker /etc/group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !newgrp abao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.24/volumes: dial unix /var/run/docker.sock: connect: permission denied\r\n"
     ]
    }
   ],
   "source": [
    "!docker volume ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a persistent `docker` volume (so that your data are not wiped out when you remove the container):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.24/volumes/create: dial unix /var/run/docker.sock: connect: permission denied\r\n"
     ]
    }
   ],
   "source": [
    "!docker volume create mongo-volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command will pull the latest `MongoDB` image from the [official image registry](https://hub.docker.com/_/mongo) and use that image to spin up a container running the DBMS. It will also set up the root credentials and use the newly created `mongo-volume` persistent volume to store the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.24/containers/create?name=mongo: dial unix /var/run/docker.sock: connect: permission denied.\r\n",
      "See 'docker run --help'.\r\n"
     ]
    }
   ],
   "source": [
    "!docker run -d --restart always --name mongo -p 27017:27017 \\\n",
    "    -v mongo-volume:/data/db \\\n",
    "    -e MONGO_INITDB_ROOT_USERNAME=mongoadmin \\\n",
    "    -e MONGO_INITDB_ROOT_PASSWORD=mongoadminsecret \\\n",
    "    mongo:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the container is up and running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.24/containers/json?all=1: dial unix /var/run/docker.sock: connect: permission denied\r\n"
     ]
    }
   ],
   "source": [
    "!docker ps -a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database is up and running and we can proceed working with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you are done with this exercise, to stop and remove the container, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !docker stop mongo && docker rm -f mongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove the persistent volume, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !docker volume rm mongo-volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### python libraries:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to install the following python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pymongo requests matplotlib numpy pandas astropy tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why use MongoDB in astronomy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`MongoDB`](https://www.mongodb.com/what-is-mongodb), the [most popular and feature-rich document-based NoSQL database to date](https://db-engines.com/en/ranking), naturally fits a number of use cases in astronomy, especially in modern time-domain astronomy.\n",
    "\n",
    "- Uses <a href=\"https://www.mongodb.com/json-and-bson\" target=\"_blank\">BSON</a> (serialized binary python-dictionary-like structures) documents to store the data in collections (a rough analog of a table in the RDBMS world). \n",
    "    - Natural to store alerts from sky surves such as ZTF or the upcoming [LSST](https://www.lsst.org/). For example, the widely used [AVRO](https://avro.apache.org/) format directly translates into BSON. \n",
    "    - Astronomical object light curves - 1 read per source to extract all data points for a source as opposed to multiple joins if RDBMS were used (one row per data point).\n",
    "- Giant [B-tree](https://en.wikipedia.org/wiki/B-tree): O(log(N)) guaranteed for search, insert, and delete operations, where N is the number of documents in a collection\n",
    "    - blazing fast with (multiple) clever (compound) indexes and covered queries\n",
    "- No schema by default but can be enforced if need be\n",
    "    - No downtime when the incoming data schema changes, e.g. the alert packet schema evolves over time\n",
    "- Built-in [GeoJSON support with 2D indices on the sphere](https://docs.mongodb.com/manual/reference/geojson/)\n",
    "    - Positional queries (e.g. cone-searches) are supported out of the box with excellent performance\n",
    "- [MongoDB Query Language (MQL)](https://docs.mongodb.com/manual/tutorial/query-documents/): cone and general searches, aggregation pipelines\n",
    "    - Supports LEFT-OUTER-JOIN-like operations\n",
    "- Horizontal scale-out\n",
    "    - Sharding supported out-of-the box\n",
    "- ACID-compliant transactions:\n",
    "    - As of version `4.2` supports transactions and is ACID-compliant even across sharded clusters\n",
    "    \n",
    "For a very quick intro into MongoDB, watch [MongoDB in 5 Minutes with Eliot Horowitz](https://www.youtube.com/watch?v=EE8ZTQxa0AM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Public transient alerts from the Zwicky Transient Facility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Zwicky Transient Facility (ZTF)](https://ztf.caltech.edu) is a state-of-the-art robotic optical sky survey currently in operation at the Palomar Observatory in Southern California. ZTF performs accurate measurements of billions of astronomical objects and registers millions of transient \"events\" (such as, for example, supernova explosions, brightness changes in variable stars, or asteroids) in the dynamic sky every (clear) night."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Events observed by ZTF may have been triggered from a flux-transient, a reoccurring flux-variable, or a moving object. The metadata and contextual information including the cutouts are put into \"alert packets\" that are distributed via the ZTF Alert Distribution System (ZADS). On a typical night, the number of detected events ranges from $10^5 - 10^6$.\n",
    "\n",
    "<table><tr><td><img src='img/fig-ztf.png'></td><td><img src='img/fig-ztf_alerts.png'></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alert sample\n",
    "\n",
    "In this exercise, we will work with a small set of public ZTF alerts (~300) originating from SNe, AGN, variable stars, asteroids, and bogus events.\n",
    "\n",
    "The setup we'll be dealing with actually mimics how things work [in production](https://arxiv.org/pdf/1907.11259.pdf), where we store the processed contents of the alerts in two `MongoDB` collections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#777'>\n",
    "Why are the data stored in two collections? To optimize data storage/querying and to remove redundant data, the alert data are dealt with as follows.\n",
    "\n",
    "Individual alerts minus the prv_candidates block are stored in the `ZTF_alerts` collection. Machine learning models are executed on individual alerts and the results are save to the `classifications` block.\n",
    "\n",
    "The contents of the `prv_candidates` blocks of individual alerts are stored in the `ZTF_alerts_aux` collection per `objectId`. No filtering is applied, however all duplicate entries originating from different alerts are removed. [In rare cases, there may be both a detection and a non-detection for the same value of `candidate.jd` due to uncertanties in the astrometry.] The data in `prv_candidates` are stored as a set meaning that they are not ordered. Additionally, the information on cross-matched sources from external catalogs (within $5\"$) is saved to the `cross_matches` block.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first fetch the dumps of the two collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in ('ZTF_alerts.dump', 'ZTF_alerts_aux.dump'):\n",
    "    if not pathlib.Path(f).exists():\n",
    "        print(f'Fetching {f}')\n",
    "        subprocess.run(['wget', f'https://storage.googleapis.com/ztf-fritz/{f}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert the dumps into our running database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no such directory\n",
      "no such directory\n",
      "Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.24/containers/mongo/json: dial unix /var/run/docker.sock: connect: permission denied\n",
      "Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.24/containers/mongo/json: dial unix /var/run/docker.sock: connect: permission denied\n",
      "Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.24/containers/mongo/json: dial unix /var/run/docker.sock: connect: permission denied\n"
     ]
    }
   ],
   "source": [
    "!docker cp ZTF_alerts.dump mongo:/tmp/\n",
    "!docker cp ZTF_alerts_aux.dump mongo:/tmp/\n",
    "\n",
    "!docker exec -it mongo \\\n",
    "    mongorestore -u=mongoadmin -p=mongoadminsecret --authenticationDatabase=admin \\\n",
    "    --archive=/tmp/ZTF_alerts.dump --drop\n",
    "\n",
    "!docker exec -it mongo \\\n",
    "    mongorestore -u=mongoadmin -p=mongoadminsecret --authenticationDatabase=admin \\\n",
    "    --archive=/tmp/ZTF_alerts_aux.dump --drop\n",
    "\n",
    "!docker exec -it mongo rm /tmp/ZTF_alerts.dump /tmp/ZTF_alerts_aux.dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import some python libraries and helper functions (see [utils.py](utils.py)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3551bb5e5657>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpymongo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0massemble_lc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_triplet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_triplet_lc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "import numpy as np\n",
    "import pymongo\n",
    "import tqdm\n",
    "from utils import assemble_lc, make_dataframe, make_triplet, plot_triplet_lc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a user for the main database that we will call `kowalski` (after a penguin):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user(username='ztf', password='ztfrulez', host='localhost', port=27017, verbose=True):\n",
    "    _client = pymongo.MongoClient(username='mongoadmin', password='mongoadminsecret', \n",
    "                                  host=host, port=port)\n",
    "\n",
    "    # _id: db_name.user_name\n",
    "    user_ids = []\n",
    "    for _u in _client.admin.system.users.find({}, {'_id': 1}):\n",
    "        user_ids.append(_u['_id'])\n",
    "\n",
    "    if verbose:\n",
    "        print(user_ids)\n",
    "\n",
    "    db_name = 'kowalski'\n",
    "\n",
    "    _mongo = _client[db_name]\n",
    "\n",
    "    if f'{db_name}.{username}' not in user_ids:\n",
    "        _mongo.command('createUser', username, pwd=password, roles=['readWrite'])\n",
    "        if verbose:\n",
    "            print('Successfully initialized db')\n",
    "\n",
    "    _mongo.client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish a connection to the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_db(host='localhost', port=27017, user='ztf', password='ztfrulez'):\n",
    "    _client = pymongo.MongoClient(host=host, port=port)\n",
    "    # grab main database:\n",
    "    _db = _client['kowalski']\n",
    "    # authenticate\n",
    "    _db.authenticate(user, password)\n",
    "    \n",
    "    return _db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = connect_to_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the alert database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us learn by example and construct and execute several queries to demonstrate some of `MongoDB`'s capabilities. But first let's discuss some performance considerations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collection methods/operations\n",
    "\n",
    "`MongoDB` supports a wide range of [collection-level operation](https://api.mongodb.com/python/current/api/pymongo/collection.html). The ones listed below are most useful for querying the data:\n",
    "\n",
    "- The `find` method is used to query a collection using a filter expression. The users have control over, in particular, the result projection/size restriction and index \"hints\".\n",
    "\n",
    "- The `find_one` method is similar to `find`, but returns the first filter expression match and does not allow result projection.\n",
    "\n",
    "- The `count_documents` method is used to count the number of documents in a collection that match a particular filter expression. \n",
    "\n",
    "- The `aggregate` method is used to execute aggregation pipelines on a colection potentially involving complicated computations and/or/involving (left outer) joins with other collections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When querying your data, you want to minimize the required I/O operations. Indexes on \"fields\" (think \"columns\" in `SQL`/table-speak) provide a fast way to find the location of a \"document\" (think catalog entry) on disk for further retrieval, or even fetching the field value if no other data is needed (so-called \"covered queries\"). \n",
    "- Indexes may be compound to speed-up multi-field queries / enable multi-field covered queries (see below for more details). \n",
    "- Whenever possible, construct your queries to use indexes. A query that cannot use an index will initiate a full collection (catalog) scan, which for large catalogs may be very costly in terms of I/O = time/performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create an example index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db['ZTF_alerts'].create_index([\n",
    "    ('coordinates.radec_geojson', '2dsphere'), \n",
    "    ('objectId', -1),\n",
    "    ('candid', -1),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now whenever you are querying the alert collection by sky position, it will be very fast to grab the alert's fields `objectId` and `candid` -- the DBMS will not even need to look at the stored documents themselves, just the index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database wants to minimize I/O, too, so when you make a query, it will first try to find an index to speed up your query. You can explicitely provide it with a `hint` on what index to try and use (see below).\n",
    "\n",
    "<div style=\"color: #721c24;\n",
    "    background-color: #f8d7da;\n",
    "    border-color: #f5c6cb;\n",
    "    padding: .75rem 1.25rem;\n",
    "    margin-bottom: 1rem;\n",
    "    border: 1px solid transparent;\n",
    "    border-radius: .25rem;\">\n",
    "    If the database fails to find such an index, it will have to look at the individual documents on disk.\n",
    "    <br><br>\n",
    "    The same applies if you make a typo and query the <tt>ZTF_alerts</tt> catalog for, for example, \"objectID\" or \"candidate.objectId\" (both don't exist) instead of \"objectId\", the database will have to look at <b>all</b> entries in the database.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compound indexes and prefixes\n",
    "\n",
    "See a detailed discussion of compound indexes in `MongoDB` [here](https://docs.mongodb.com/manual/core/index-compound/).\n",
    "\n",
    "`MongoDB` supports compound indexes, where a single index structure holds references to multiple fields within a collection's documents. Compound indexes can support queries that match on multiple fields.\n",
    "\n",
    "##### Prefixes\n",
    "\n",
    "Index prefixes are the beginning subsets of indexed fields. For example, consider the compound index #9 above:\n",
    "\n",
    "```python\n",
    "[['candidate.jd', -1], ['classifications.braai', -1], ['candid', -1]]\n",
    "```\n",
    "\n",
    "The index has the following index prefixes:\n",
    "\n",
    "```python\n",
    "{'candidate.jd': -1}\n",
    "{'candidate.jd': -1, 'classifications.braai': -1}\n",
    "```\n",
    "\n",
    "For a compound index, `MongoDB` can use the index to support queries on the index prefixes. As such, `MongoDB` can use the index for queries on the following fields:\n",
    "\n",
    "- the `candidate.jd` field,\n",
    "- the `candidate.jd` field and the `classifications.braai` field,\n",
    "- the `candidate.jd` field and the `classifications.braai` field and the `candid` field.\n",
    "\n",
    "`MongoDB` can also use the index to support a query on `candidate.jd` and `candid` fields since `candidate.jd` field corresponds to a prefix. However, the index would not be as efficient in supporting the query as would be an index on only `candidate.jd` and `candid`.\n",
    "\n",
    "However, `MongoDB` cannot use the index to support queries that include the following fields since without the item field, none of the listed fields correspond to a prefix index:\n",
    "\n",
    "- the `classifications.braai` field,\n",
    "- the `candid` field, or\n",
    "- the `classifications.braai` and `candid` fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of alerts in our database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db['ZTF_alerts'].count_documents({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of alerts in our database that have a deep real-bogus score of >=0.9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db['ZTF_alerts'].count_documents({'candidate.drb': {'$gt': 0.9}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of alerts in our database that have a deep real-bogus score between 0.1 and 0.9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db['ZTF_alerts'].count_documents({'candidate.drb': {'$gt': 0.1, '$lt': 0.9}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all ZTF alerts with a given `objectId` and return the full contents of the alert packets excluding the image cutouts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = db['ZTF_alerts'].find(\n",
    "    {\n",
    "        'objectId': 'ZTF20aaelulu'\n",
    "    },\n",
    "    {\n",
    "        'cutoutScience': 0,\n",
    "        'cutoutTemplate': 0,\n",
    "        'cutoutDifference': 0\n",
    "    }\n",
    ")\n",
    "list(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the `objectId`'s and `candids` of ZTF alerts [detected](https://iopscience.iop.org/article/10.3847/2515-5172/ab459c#rnaasab459cbib10) in the [TESS](https://tess.mit.edu/) northern fields after April 25, 2020:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = db['ZTF_alerts'].find(\n",
    "    {\n",
    "        'candidate.jd': {'$gt': 2458964.5},\n",
    "        'candidate.programpi': 'TESS'\n",
    "    },\n",
    "    {\n",
    "        '_id': 0,\n",
    "        'objectId': 1,\n",
    "        'candid': 1\n",
    "    }\n",
    ")\n",
    "list(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get time-stamped (difference image) magnitude measurements and drb scores for all detections of object `ZTF18acmfmow` with a drb score of >= 0.9 and sort them by observation Julian date in descending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = db['ZTF_alerts'].find(\n",
    "    {\n",
    "        'objectId': 'ZTF20aapcmur', \n",
    "        'candidate.drb': {'$gte': 0.9}\n",
    "    },\n",
    "    {\n",
    "        '_id': 0, \n",
    "        'candidate.jd': 1, \n",
    "        'candidate.magpsf': 1, \n",
    "        'candidate.drb': 1,\n",
    "    }\n",
    ").sort([('candidate.jd', -1)])\n",
    "list(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aggregation pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all ZTF transient `objectId`'s that have more than 10 associated alerts in our database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = db['ZTF_alerts'].aggregate(\n",
    "    [\n",
    "        {'$group' : {'_id': '$objectId', 'count': {'$sum': 1}}}, \n",
    "        {'$match': {'count' : {'$gt': 10}}}, \n",
    "        {'$project': {'objectId' : '$_id', '_id' : 0}},\n",
    "    ]\n",
    ")\n",
    "list(cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all ZTF transient `objectId`'s that have more than 4 associated alerts in our database, each with a deep real-bogus score of >= 0.7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = db['ZTF_alerts'].aggregate(\n",
    "    [\n",
    "        {'$group': {\n",
    "            '_id': '$objectId', \n",
    "            'count': { '$sum': {'$cond': [ { '$gte': [ '$candidate.drb', 0.7 ] }, 1, 0]} } \n",
    "        }},\n",
    "        {'$match': {'count' : {'$gt': 4} } }, \n",
    "        {'$project': {'objectId' : '$_id', '_id' : 0} }\n",
    "    ]\n",
    ")\n",
    "list(cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following aggregation pipeline first performs a left outer join of the `ZTF_alerts` collection with the `ZTF_alerts_aux` collection by `objectId` and makes the results look like they were stored in single documents. The last stage of the pipeline outputs a random alert sample of size 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = db['ZTF_alerts'].aggregate([\n",
    "    {\n",
    "        \"$lookup\": {\n",
    "            \"from\": \"ZTF_alerts_aux\",\n",
    "            \"localField\": \"objectId\",\n",
    "            \"foreignField\": \"_id\",\n",
    "            \"as\": \"aux\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$replaceRoot\": {\n",
    "            \"newRoot\": {\n",
    "                \"$mergeObjects\": [\n",
    "                    {\n",
    "                        \"$arrayElemAt\": [\n",
    "                            \"$aux\",\n",
    "                            0\n",
    "                        ]\n",
    "                    },\n",
    "                    \"$$ROOT\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$sample': {\n",
    "            'size': 10\n",
    "        }\n",
    "    }\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the sample alert cutouts and light curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_alert_triplet_lc(alert, match_radius_arcsec=1.5, star_galaxy_threshold=0.4):\n",
    "    display.display(\n",
    "        display.HTML(\n",
    "            f\"<b>objectId</b>: {alert['objectId']}, \"\n",
    "            f\"<b>candid</b>: {alert['candid']}, \"\n",
    "            f\"<b>real/bogus score</b>: {alert['candidate'].get('drb', alert['candidate']['rb']):.3f}\"\n",
    "        )\n",
    "    )\n",
    "            \n",
    "    tr = make_triplet(alert)\n",
    "    \n",
    "    df = make_dataframe(alert)\n",
    "    \n",
    "    _, lc_candid = assemble_lc(df, objectId=alert['objectId'], composite=False,\n",
    "                                   match_radius_arcsec=match_radius_arcsec,\n",
    "                                   star_galaxy_threshold=star_galaxy_threshold)\n",
    "\n",
    "    plot_triplet_lc(tr, lc_candid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alert in cursor:\n",
    "    display_alert_triplet_lc(alert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `coordinates.radec_geojson` field defined for every object in our `ZTF_alerts` collection has an associated spherical 2D index, which allows for efficient positional queries. `MongoDB` supports many query operators, see [here](https://docs.mongodb.com/manual/reference/operator/query-geospatial/) for more details. The caveat to keep in mind is the following: `MongoDB` uses `GeoJSON` objects to represent `2D` positions on the sphere. Both the longitude (`R.A.`) and latitude (`Decl.`) must be expressed in decimal degrees, and the valid longitude values are between `-180` and `180`, both inclusive, so you must subtract 180.0 degrees from your `R.A.` value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a helper function for cone searches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cone_search(_db, collection='ZTF_alerts',\n",
    "                ra=0.0, dec=0.0, radius=1.0, unit='arcsec',\n",
    "                projection=None):\n",
    "    # cone search radius:\n",
    "    cone_search_radius = float(radius)\n",
    "    # convert to rad:\n",
    "    if unit == 'arcsec':\n",
    "        cone_search_radius *= np.pi / 180.0 / 3600.\n",
    "    elif unit == 'arcmin':\n",
    "        cone_search_radius *= np.pi / 180.0 / 60.\n",
    "    elif unit == 'deg':\n",
    "        cone_search_radius *= np.pi / 180.0\n",
    "    elif unit == 'rad':\n",
    "        cone_search_radius *= 1\n",
    "    else:\n",
    "        raise Exception('Unknown cone search unit. Must be in [deg, rad, arcsec, arcmin]')\n",
    "    \n",
    "    # fields to return: everything by default\n",
    "    if projection is None:\n",
    "        projection = dict()\n",
    "    \n",
    "    cursor = _db[collection].find({}, projection)\n",
    "    \n",
    "    cursor = db['ZTF_alerts'].aggregate([\n",
    "        {\n",
    "            \"$match\": {\n",
    "                'coordinates.radec_geojson': {\n",
    "                    '$geoWithin': {\n",
    "                        '$centerSphere': [[ra - 180.0, dec], cone_search_radius]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$lookup\": {\n",
    "                \"from\": \"ZTF_alerts_aux\",\n",
    "                \"localField\": \"objectId\",\n",
    "                \"foreignField\": \"_id\",\n",
    "                \"as\": \"aux\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$replaceRoot\": {\n",
    "                \"newRoot\": {\n",
    "                    \"$mergeObjects\": [\n",
    "                        {\n",
    "                            \"$arrayElemAt\": [\n",
    "                                \"$aux\",\n",
    "                                0\n",
    "                            ]\n",
    "                        },\n",
    "                        \"$$ROOT\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ])\n",
    "    \n",
    "    return cursor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us look for some transients in <a href=\"https://en.wikipedia.org/wiki/Messier_100\" target=\"_blank\">Messier 100</a>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alerts = list(\n",
    "    cone_search(db, ra=185.7287500, dec=15.8225000, radius=30.0, unit='arcsec', projection={'_id': 0})\n",
    ")\n",
    "\n",
    "for alert in alerts:\n",
    "    display_alert_triplet_lc(alert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further studying\n",
    "\n",
    "<a href=\"https://www.coursera.org/learn/introduction-mongodb\" target=\"_blank\">Introduction to MongoDB official class <i class=\"fa fa-external-link\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "<a href=\"https://www.datacamp.com/community/tutorials/introduction-mongodb-python\" target=\"_blank\">Introduction to MongoDB and Python <i class=\"fa fa-external-link\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "<a href=\"https://docs.mongodb.com/manual/reference/sql-aggregation-comparison/\" target=\"_blank\">SQL to MongoDB Aggregation Mapping Chart <i class=\"fa fa-external-link\" aria-hidden=\"true\"></i></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
